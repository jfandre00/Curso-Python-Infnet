{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP3 Python para Dados - André L. M. Ferreira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
      "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City  ...  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "\n",
      "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Carregue o dataset Superstore em um DataFrame Pandas.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Sample - Superstore.csv\", encoding='ISO-8859-1')\n",
    "# encoding='ISO-8859-1' é a mesma coisa que encoding='latin1'. Precisei fazer isso para conseguir ler o arquivo corretamente, após tentar com utf-8 e utf-16 e também sem encoding nenhum. Encontrei essa solução no stackoverflow: https://stackoverflow.com/questions/18171739/unicodedecodeerror-when-reading-csv-file-in-pandas-with-python\n",
    "\n",
    "# 1.2 Exiba as 5 primeiras linhas do DataFrame.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row ID             int64\n",
      "Order ID          object\n",
      "Order Date        object\n",
      "Ship Date         object\n",
      "Ship Mode         object\n",
      "Customer ID       object\n",
      "Customer Name     object\n",
      "Segment           object\n",
      "Country           object\n",
      "City              object\n",
      "State             object\n",
      "Postal Code        int64\n",
      "Region            object\n",
      "Product ID        object\n",
      "Category          object\n",
      "Sub-Category      object\n",
      "Product Name      object\n",
      "Sales            float64\n",
      "Quantity           int64\n",
      "Discount         float64\n",
      "Profit           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Verifique os tipos das colunas do DataFrame.\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9994, 21)\n"
     ]
    }
   ],
   "source": [
    "# 1.5 Conte o número de linhas e colunas do DataFrame.\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row ID           0\n",
      "Order ID         0\n",
      "Order Date       0\n",
      "Ship Date        0\n",
      "Ship Mode        0\n",
      "Customer ID      0\n",
      "Customer Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal Code      0\n",
      "Region           0\n",
      "Product ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product Name     0\n",
      "Sales            0\n",
      "Quantity         0\n",
      "Discount         0\n",
      "Profit           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1.6 Verifique se há valores nulos e quantos são.\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (517360038.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[97], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install openpyxl\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl\n",
    "\n",
    "# Antes de executar o exercício 2, foi necessário seguir os passos acima:\n",
    "# Pois estava dando um erro \"No module named 'openpyxl'\", encontrei a solução no stackoverflow: https://stackoverflow.com/questions/63180563/how-to-fix-no-module-named-openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
      "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City  ...  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "\n",
      "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Salve o dataset em um arquivo Excel e carregue-o novamente.\n",
    "\n",
    "df.to_excel(\"Sample - Superstore.xlsx\", index=False, engine='openpyxl')\n",
    "df2 = pd.read_excel(\"Sample - Superstore.xlsx\", engine='openpyxl')\n",
    "\n",
    "print(df2.head())  # Confirmando se os dados foram carregados corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156 2016-11-08  11/11/2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156 2016-11-08  11/11/2016    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688 2016-06-12   6/16/2016    Second Class    DV-13045   \n",
      "3      14  CA-2016-161389 2016-12-05  12/10/2016  Standard Class    IM-15070   \n",
      "4      22  CA-2016-137330 2016-12-09  12/13/2016  Standard Class    KB-16585   \n",
      "\n",
      "     Customer Name    Segment        Country         City  ... Postal Code  \\\n",
      "0      Claire Gute   Consumer  United States    Henderson  ...       42420   \n",
      "1      Claire Gute   Consumer  United States    Henderson  ...       42420   \n",
      "2  Darrin Van Huff  Corporate  United States  Los Angeles  ...       90036   \n",
      "3     Irene Maddox   Consumer  United States      Seattle  ...       98103   \n",
      "4        Ken Black  Corporate  United States      Fremont  ...       68025   \n",
      "\n",
      "    Region       Product ID         Category Sub-Category  \\\n",
      "0    South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1    South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2     West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3     West  OFF-BI-10003656  Office Supplies      Binders   \n",
      "4  Central  OFF-AR-10000246  Office Supplies          Art   \n",
      "\n",
      "                                        Product Name    Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.960         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.940         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.620         2   \n",
      "3        Fellowes PB200 Plastic Comb Binding Machine  407.976         3   \n",
      "4                                         Newell 318   19.460         7   \n",
      "\n",
      "   Discount    Profit  \n",
      "0       0.0   41.9136  \n",
      "1       0.0  219.5820  \n",
      "2       0.0    6.8714  \n",
      "3       0.2  132.5922  \n",
      "4       0.0    5.0596  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Combine dois arquivos Excel contendo pedidos de anos diferentes usando pd.concat().\n",
    "\n",
    "# Primeiro passo é criar dois DataFrames com os dados de 2016 e 2017.\n",
    "df_2016 = df[df[\"Order Date\"].dt.year == 2016]\n",
    "df_2017 = df[df[\"Order Date\"].dt.year == 2017]\n",
    "\n",
    "# Agora, vamos salvar esses DataFrames em abas dentro de um arquivo Excel.\n",
    "# Novamente precisei usar o engine='openpyxl' para conseguir salvar o arquivo.\n",
    "with pd.ExcelWriter(\"Orders_Divididas.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    df_2016.to_excel(writer, sheet_name=\"2016\", index=False)\n",
    "    df_2017.to_excel(writer, sheet_name=\"2017\", index=False)\n",
    "\n",
    "# Agora, vamos carregar esses arquivos e combiná-los em um único DataFrame.\n",
    "df_2016 = pd.read_excel(\"Orders_Divididas.xlsx\", sheet_name=\"2016\", engine=\"openpyxl\")\n",
    "df_2017 = pd.read_excel(\"Orders_Divididas.xlsx\", sheet_name=\"2017\", engine=\"openpyxl\")\n",
    "\n",
    "# E finalmente, vamos combinar os dois DataFrames em um único DataFrame.\n",
    "df_combinado = pd.concat([df_2016, df_2017], ignore_index=True)\n",
    "\n",
    "# Como teste, vou salvar o DataFrame combinado em um arquivo Excel.\n",
    "df_combinado.to_excel(\"Orders_Combinadas.xlsx\", index=False)\n",
    "\n",
    "print(df_combinado.head())  # Exibindo as primeiras linhas do DataFrame combinado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
      "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City  ...  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "\n",
      "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Crie um banco de dados SQLite e uma tabela pedidos.\n",
    "\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"superstore.db\")\n",
    "\n",
    "# 3.2 Insira os dados do DataFrame na tabela SQL. Casi a tabela já exista, substitua-a.\n",
    "\n",
    "df.to_sql(\"orders\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# 3.3 Carregue os dados do banco SQL para um DataFrame Pandas.\n",
    "\n",
    "df_sql = pd.read_sql(\"SELECT * FROM orders\", conn)\n",
    "\n",
    "print(df_sql.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID           Order Date   Ship Date       Ship Mode  \\\n",
      "0       2  CA-2016-152156  2016-11-08 00:00:00  11/11/2016    Second Class   \n",
      "1      14  CA-2016-161389  2016-12-05 00:00:00  12/10/2016  Standard Class   \n",
      "2      25  CA-2015-106320  2015-09-25 00:00:00   9/30/2015  Standard Class   \n",
      "3      36  CA-2016-117590  2016-12-08 00:00:00  12/10/2016     First Class   \n",
      "4      55  CA-2016-105816  2016-12-11 00:00:00  12/17/2016  Standard Class   \n",
      "\n",
      "  Customer ID   Customer Name    Segment        Country           City  ...  \\\n",
      "0    CG-12520     Claire Gute   Consumer  United States      Henderson  ...   \n",
      "1    IM-15070    Irene Maddox   Consumer  United States        Seattle  ...   \n",
      "2    EB-13870     Emily Burns   Consumer  United States           Orem  ...   \n",
      "3    GH-14485       Gene Hale  Corporate  United States     Richardson  ...   \n",
      "4    JM-15265  Janet Molinari  Corporate  United States  New York City  ...   \n",
      "\n",
      "  Postal Code   Region       Product ID         Category Sub-Category  \\\n",
      "0       42420    South  FUR-CH-10000454        Furniture       Chairs   \n",
      "1       98103     West  OFF-BI-10003656  Office Supplies      Binders   \n",
      "2       84057     West  FUR-TA-10000577        Furniture       Tables   \n",
      "3       75080  Central  TEC-PH-10004977       Technology       Phones   \n",
      "4       10024     East  TEC-PH-10002447       Technology       Phones   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0  Hon Deluxe Fabric Upholstered Stacking Chairs,...   731.940         3   \n",
      "1        Fellowes PB200 Plastic Comb Binding Machine   407.976         3   \n",
      "2      Bretford CR4500 Series Slim Rectangular Table  1044.630         3   \n",
      "3                                        GE 30524EE4  1097.544         7   \n",
      "4                   AT&T CL83451 4-Handset Telephone  1029.950         5   \n",
      "\n",
      "   Discount    Profit  \n",
      "0       0.0  219.5820  \n",
      "1       0.2  132.5922  \n",
      "2       0.0  240.2649  \n",
      "3       0.2  123.4737  \n",
      "4       0.0  298.6855  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 4. Consultas SQL básicas\n",
    "# 4.1 Selecione todos os pedidos com lucro maior de R$ 100,00.\n",
    "\n",
    "df_lucro_maior_100 = pd.read_sql(\"SELECT * FROM orders WHERE Profit > 100\", conn)\n",
    "\n",
    "print(df_lucro_maior_100.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID           Order Date   Ship Date       Ship Mode  \\\n",
      "0       1  CA-2016-152156  2016-11-08 00:00:00  11/11/2016    Second Class   \n",
      "1       2  CA-2016-152156  2016-11-08 00:00:00  11/11/2016    Second Class   \n",
      "2       4  US-2015-108966  2015-10-11 00:00:00  10/18/2015  Standard Class   \n",
      "3       5  US-2015-108966  2015-10-11 00:00:00  10/18/2015  Standard Class   \n",
      "4       6  CA-2014-115812  2014-06-09 00:00:00   6/14/2014  Standard Class   \n",
      "\n",
      "  Customer ID    Customer Name   Segment        Country             City  ...  \\\n",
      "0    CG-12520      Claire Gute  Consumer  United States        Henderson  ...   \n",
      "1    CG-12520      Claire Gute  Consumer  United States        Henderson  ...   \n",
      "2    SO-20335   Sean O'Donnell  Consumer  United States  Fort Lauderdale  ...   \n",
      "3    SO-20335   Sean O'Donnell  Consumer  United States  Fort Lauderdale  ...   \n",
      "4    BH-11710  Brosina Hoffman  Consumer  United States      Los Angeles  ...   \n",
      "\n",
      "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "3       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "4       90032    West  FUR-FU-10001487        Furniture  Furnishings   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "3                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "4  Eldon Expressions Wood and Plastic Desk Access...   48.8600         7   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.45 -383.0310  \n",
      "3      0.20    2.5164  \n",
      "4      0.00   14.1694  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Filtre os pedidos do Segment \"Consumer\".\n",
    "\n",
    "df_segment_consumer = pd.read_sql(\"SELECT * FROM orders WHERE Segment = 'Consumer'\", conn)\n",
    "\n",
    "print(df_segment_consumer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x267550599c0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renoemando a coluna dentro do SQL \"Product Name\" para \"Product_Name\" para evitar problemas com o espaço no nome da coluna, pois tive problemas ao tentar fazer consultas com o nome da coluna com espaço.\n",
    "\n",
    "conn.execute(\"ALTER TABLE orders RENAME COLUMN 'Product Name' TO Product_Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Product_Name  Total_Quantity\n",
      "0                     Staples             215\n",
      "1             Staple envelope             170\n",
      "2           Easy-staple paper             150\n",
      "3     Staples in misc. colors              86\n",
      "4  KI Adjustable-Height Table              74\n"
     ]
    }
   ],
   "source": [
    "# 5. Consultas SQL Avançadas\n",
    "# 5.1 Liste os 5 produtos mais vendidos por quantidade.\n",
    "\n",
    "df_produtos_mais_vendidos = pd.read_sql(\n",
    "    \"SELECT Product_Name, SUM(Quantity) AS Total_Quantity \"\n",
    "    \"FROM orders \"\n",
    "    \"GROUP BY Product_Name \"\n",
    "    \"ORDER BY Total_Quantity \"\n",
    "    \"DESC LIMIT 5\"\n",
    "    , conn)\n",
    "\n",
    "# Usei o DESC LIMIT 5 para pegar os 5 produtos mais vendidos por quantidade.\n",
    "\n",
    "print(df_produtos_mais_vendidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            City  Total_Sales\n",
      "0  New York City   247347.687\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Encontre a cidade com o maior volume de vendas.\n",
    "\n",
    "df_cidade_maior_volume = pd.read_sql(\n",
    "    \"SELECT City, SUM(Sales) AS Total_Sales \"\n",
    "    \"FROM orders \"\n",
    "    \"GROUP BY City \"\n",
    "    \"ORDER BY Total_Sales \"\n",
    "    \"DESC LIMIT 1\" \n",
    "    , conn)\n",
    "\n",
    "# Usei o DESC LIMIT 1 para pegar apenas a primeira linha, que será a cidade com o maior volume de vendas.\n",
    "\n",
    "print(df_cidade_maior_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x26756c84fc0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Atualização e exclusão no banco.\n",
    "# 6.1 Exclua todos os pedidos com valor de venda menor que R$ 50,00.\n",
    "\n",
    "conn.execute(\"DELETE FROM orders WHERE Sales < 50\")\n",
    "\n",
    "# Para fazer o 6.2, precisamos criar uma coluna \"Status\" na tabela \"orders\".\n",
    "conn.execute(\"ALTER TABLE orders ADD COLUMN Status TEXT\")\n",
    "\n",
    "# 6.2 Atualize os pedidos com quantidade maior que 10 para \"Pedido em Revisão\".\n",
    "\n",
    "conn.execute(\"UPDATE orders SET Status = 'Pedido em Revisão' WHERE Quantity > 10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0     148  CA-2016-114489  12/5/2016   12/9/2016  Standard Class    JE-16165   \n",
      "1     252  CA-2016-145625  9/11/2016   9/17/2016  Standard Class    KC-16540   \n",
      "2     344  CA-2014-122336  4/13/2014   4/17/2014    Second Class    JD-15895   \n",
      "3     413  CA-2017-117457  12/8/2017  12/12/2017  Standard Class    KH-16510   \n",
      "4     576  CA-2015-149713  9/18/2015   9/22/2015    Second Class    TG-21640   \n",
      "\n",
      "      Customer Name    Segment        Country           City  ...   Region  \\\n",
      "0    Justin Ellison  Corporate  United States       Franklin  ...  Central   \n",
      "1   Kelly Collister   Consumer  United States      San Diego  ...     West   \n",
      "2  Jonathan Doherty  Corporate  United States   Philadelphia  ...     East   \n",
      "3     Keith Herrera   Consumer  United States  San Francisco  ...     West   \n",
      "4      Trudy Glocke   Consumer  United States     Long Beach  ...     West   \n",
      "\n",
      "        Product ID         Category Sub-Category  \\\n",
      "0  TEC-PH-10000215       Technology       Phones   \n",
      "1  TEC-AC-10003832       Technology  Accessories   \n",
      "2  TEC-PH-10000702       Technology       Phones   \n",
      "3  FUR-BO-10001972        Furniture    Bookcases   \n",
      "4  OFF-PA-10004530  Office Supplies        Paper   \n",
      "\n",
      "                                        Product Name     Sales Quantity  \\\n",
      "0  Plantronics Cordless Phone Headset with In-lin...   384.450       11   \n",
      "1                 Logitech P710e Mobile Speakerphone  3347.370       13   \n",
      "2  Square Credit Card Reader, 4 1/2\" x 4 1/2\" x 1...    71.928       12   \n",
      "3         O'Sullivan 4-Shelf Bookcase in Odessa Pine  1336.829       13   \n",
      "4        Personal Creations Ink Jet Cards and Labels   160.720       14   \n",
      "\n",
      "   Discount    Profit             Status  \n",
      "0      0.00  103.8015  Pedido em Revisão  \n",
      "1      0.00  636.0003  Pedido em Revisão  \n",
      "2      0.40    8.3916  Pedido em Revisão  \n",
      "3      0.15   31.4548  Pedido em Revisão  \n",
      "4      0.00   78.7528  Pedido em Revisão  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Vamos verificar se as alterações foram feitas corretamente.\n",
    "df_sql = pd.read_sql(\"SELECT * FROM orders WHERE Quantity > 10\", conn)\n",
    "\n",
    "print(df_sql.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID           Order Date   Ship Date       Ship Mode  \\\n",
      "0    2698  CA-2014-145317  2014-03-18 00:00:00   3/23/2014  Standard Class   \n",
      "1    6827  CA-2016-118689  2016-10-02 00:00:00   10/9/2016  Standard Class   \n",
      "2    8154  CA-2017-140151  2017-03-23 00:00:00   3/25/2017     First Class   \n",
      "3    2624  CA-2017-127180  2017-10-22 00:00:00  10/24/2017     First Class   \n",
      "4    4191  CA-2017-166709  2017-11-17 00:00:00  11/22/2017  Standard Class   \n",
      "\n",
      "  Customer ID Customer Name      Segment        Country           City  ...  \\\n",
      "0    SM-20320   Sean Miller  Home Office  United States   Jacksonville  ...   \n",
      "1    TC-20980  Tamara Chand    Corporate  United States      Lafayette  ...   \n",
      "2    RB-19360  Raymond Buch     Consumer  United States        Seattle  ...   \n",
      "3    TA-21385  Tom Ashbrook  Home Office  United States  New York City  ...   \n",
      "4    HL-15040  Hunter Lopez     Consumer  United States         Newark  ...   \n",
      "\n",
      "        Product ID    Category Sub-Category  \\\n",
      "0  TEC-MA-10002412  Technology     Machines   \n",
      "1  TEC-CO-10004722  Technology      Copiers   \n",
      "2  TEC-CO-10004722  Technology      Copiers   \n",
      "3  TEC-CO-10004722  Technology      Copiers   \n",
      "4  TEC-CO-10004722  Technology      Copiers   \n",
      "\n",
      "                                        Product_Name      Sales Quantity  \\\n",
      "0  Cisco TelePresence System EX90 Videoconferenci...  22638.480        6   \n",
      "1              Canon imageCLASS 2200 Advanced Copier  17499.950        5   \n",
      "2              Canon imageCLASS 2200 Advanced Copier  13999.960        4   \n",
      "3              Canon imageCLASS 2200 Advanced Copier  11199.968        4   \n",
      "4              Canon imageCLASS 2200 Advanced Copier  10499.970        3   \n",
      "\n",
      "  Discount     Profit  Status  Total_com_desconto  \n",
      "0      0.5 -1811.0784    None          11319.2400  \n",
      "1      0.0  8399.9760    None          17499.9500  \n",
      "2      0.0  6719.9808    None          13999.9600  \n",
      "3      0.2  3919.9888    None           8959.9744  \n",
      "4      0.0  5039.9856    None          10499.9700  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# 7. Criaçãop de colunas e transformações\n",
    "\n",
    "# 7.1 Crie a coluna \"Total com desconto\" que é Sales - (Sales * Discount).\n",
    "\n",
    "conn.execute(\"ALTER TABLE orders ADD COLUMN Total_com_desconto REAL\")\n",
    "conn.execute(\"UPDATE orders SET Total_com_desconto = Sales - (Sales * Discount)\")\n",
    "\n",
    "# 7.2 Preencha valores nulos com \"Não Informado\" para textos e 0 para valores numéricos.\n",
    "\n",
    "conn.execute(\"UPDATE orders SET Product_Name = 'Não Informado' WHERE Product_Name IS NULL\")\n",
    "conn.execute(\"UPDATE orders SET Total_com_desconto = 0 WHERE Total_com_desconto IS NULL\")\n",
    "\n",
    "# 7.3 Ordene o DataFrame pelo valor de venda (Sales) en ordem decrescente.\n",
    "\n",
    "df_sql = pd.read_sql(\"SELECT * FROM orders ORDER BY Sales DESC\", conn)\n",
    "\n",
    "print(df_sql.head())  # Exibindo as primeiras linhas do DataFrame ordenado por Sales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            City  Media_Vendas\n",
      "0          Akron    258.808600\n",
      "1    Albuquerque    231.786000\n",
      "2     Alexandria    761.934286\n",
      "3          Allen    244.006000\n",
      "4      Allentown    381.330000\n",
      "..           ...           ...\n",
      "467   Woonsocket     52.205000\n",
      "468      Yonkers    833.008000\n",
      "469         York    247.331333\n",
      "470      Yucaipa     50.800000\n",
      "471         Yuma    392.756500\n",
      "\n",
      "[472 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 8. Agrupe os pedidos por cidade e calcule a média de vendas.\n",
    "\n",
    "df_media_vendas_cidade = pd.read_sql(\n",
    "    \"SELECT City, AVG(Sales) AS Media_Vendas \"\n",
    "    \"FROM orders \"\n",
    "    \"GROUP BY City\"\n",
    "    , conn)\n",
    "\n",
    "print(df_media_vendas_cidade)  # Exibindo a média de vendas por cidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O arquivo não foi encontrado. Verifique o caminho e tente novamente.\n"
     ]
    }
   ],
   "source": [
    "# 9. Tratamento de erros - Arquivo inexistente. Tente carregar um arquivo CSV inexistente e trate o erro com try/except, exibindo uma mensagem amigável.\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"arquivo_inexistente.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"O arquivo não foi encontrado. Verifique o caminho e tente novamente.\")\n",
    "except Exception as e:\n",
    "    print(\"Ocorreu um erro ao tentar carregar o arquivo:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhuma quantidade negativa encontrada.\n"
     ]
    }
   ],
   "source": [
    "# 10. Tratamento de valores inválidos - Verifique se a coluna \"Quantity\" contém apenas valores positivos e se houver exiba um alerta e corrija-os.\n",
    "\n",
    "df_quantidade_negativa = pd.read_sql(\"SELECT * FROM orders WHERE Quantity < 0\", conn)\n",
    "\n",
    "if not df_quantidade_negativa.empty:\n",
    "    print(\"Quantidades negativas encontradas. Corrigindo...\")\n",
    "    conn.execute(\"UPDATE orders SET Quantity = 0 WHERE Quantity < 0\")\n",
    "else:\n",
    "    print(\"Nenhuma quantidade negativa encontrada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocorreu um erro ao tentar carregar o arquivo: 'utf-8' codec can't decode byte 0xa0 in position 2944: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "# 11. Bloco 'else' em exceções - Tente abrir um arquivo. Se for carregado com sucesso, exiba \"Arquivo carregado com sucesso\". Caso contrário, trate o erro.\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"Sample - Superstore.csv\")\n",
    "except Exception as e:\n",
    "    print(\"Ocorreu um erro ao tentar carregar o arquivo:\", e)\n",
    "else:\n",
    "    print(\"Arquivo carregado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo não encontrado. Verifique o nome do arquivo.\n"
     ]
    }
   ],
   "source": [
    "# 12. Tratamento de FileNotFoundError - Tente abrir um arquivo chamado \"dados_inexistentes.csv\" e trate a exceção, exibindo \"Arquivo não encontrado. Verifique o nome do arquivo.\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"dados_inexistentes.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado. Verifique o nome do arquivo.\")\n",
    "except Exception as e:\n",
    "    print(\"Ocorreu um erro ao tentar carregar o arquivo:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O código continuou a ser executado após a exceção.\n"
     ]
    }
   ],
   "source": [
    "# 13. Uso de pass para silenciar falhas - Tente abrir um arquivo que pode ou não existir. Se houver erro, use pass para continuar a execução sem interrupções.\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"dados_inexistentes.csv\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "print(\"O código continuou a ser executado após a exceção.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedidos com lucro positivo salvos em 'pedidos_lucrativos.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 14. Exportação de resultados - Filtre pedidos com lucro positivo e salve o resultado em m novo arquivo CSV chamado \"pedidos_lucrativos.csv\".\n",
    "\n",
    "df_lucro_positivo = pd.read_sql(\"SELECT * FROM orders WHERE Profit > 0\", conn)\n",
    "df_lucro_positivo.to_csv(\"pedidos_lucrativos.csv\", index=False)\n",
    "\n",
    "print(\"Pedidos com lucro positivo salvos em 'pedidos_lucrativos.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo de vendas salvo em 'resumo_vendas.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 15. Automação de análise de vendas - Crie um script que carregue o dataset, filtre pedidos com lucro positivo, calcule o total de vendas por cidade e exporte o resultado para \"resumo_vendas.csv\". \n",
    "\n",
    "df = pd.read_csv(\"Sample - Superstore.csv\", encoding='ISO-8859-1')\n",
    "df = df[df[\"Profit\"] > 0]\n",
    "df_resumo_vendas = df.groupby(\"City\")[\"Sales\"].sum().reset_index()\n",
    "# Usei o reset_index() para transformar a série resultante em um DataFrame.\n",
    "df_resumo_vendas.to_csv(\"resumo_vendas.csv\", index=False)\n",
    "\n",
    "print(\"Resumo de vendas salvo em 'resumo_vendas.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de vendas salvo em 'relatorio_vendas.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# 16. Criação de um relatório dinâmico - Usando Pandas, gere um relatório de vendas por categoria agrupando os dados e exporte os resultados para um arquivo Excel com multiplas abas (uma aba por categoria).\n",
    "\n",
    "df = pd.read_csv(\"Sample - Superstore.csv\", encoding='ISO-8859-1')\n",
    "categorias = df[\"Category\"].unique()\n",
    "# Usei o método unique() para obter as categorias únicas. Dando uma olhada no DataFrame, vi que temos somente 3 categorias: \"Furniture\", \"Office Supplies\" e \"Technology\".\n",
    "\n",
    "with pd.ExcelWriter(\"relatorio_vendas.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    for categoria in categorias:\n",
    "        df_categoria = df[df[\"Category\"] == categoria]\n",
    "        df_categoria.to_excel(writer, sheet_name=categoria, index=False)\n",
    "\n",
    "print(\"Relatório de vendas salvo em 'relatorio_vendas.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com o banco de dados encerrada.\n"
     ]
    }
   ],
   "source": [
    "# Aqui iremos fechar a conexão com o banco de dados pois o TP3 chegou ao fim.\n",
    "\n",
    "conn.close()\n",
    "print(\"Conexão com o banco de dados encerrada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
