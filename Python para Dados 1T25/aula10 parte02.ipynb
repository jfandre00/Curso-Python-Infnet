{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping com Python\n",
    "\n",
    "técnicas para baixar e analisar páginas HTML\n",
    "usaremos bibliotecas urllib e BeautifulSoup para extrair informações da web\n",
    "\n",
    "\n",
    "-> podemos coletar dados de sites para análise\n",
    "-> automatizar tarefas repetitivas\n",
    "-> monitorar sites dinamicamente\n",
    "\n",
    "### 2 estapas principais\n",
    "\n",
    "1. Crawler (Coletor de Dados) - acessa sites, lê o HTML e baixa a página \n",
    "2. Parser (Analisados de Conteúdo) - lê o HTML baixado e extrai informações específicas (títulos, links, imagens, etc).\n",
    "\n",
    "Em Python, usamos o BeautifulSoup para processar e encontrar dados no HTML.\n",
    "\n",
    "#### O que há por trás (HTML, CSS e HTTP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n    '\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://example.com\"\n",
    "response = urllib.request.urlopen(url)\n",
    "html = response.read()\n",
    "\n",
    "print(html[:500]) # print the first 500 characters of the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá, Mundo!\n"
     ]
    }
   ],
   "source": [
    "# BeautifulSoup is a Python library for parsing HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html= \"<html><body><h1>Olá, Mundo!</h1></body></html>\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "print(soup.h1.text) # print the text inside the <h1> tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiro parágrafo\n",
      "Segundo parágrafo\n"
     ]
    }
   ],
   "source": [
    "html = \"<html><body><p>Primeiro parágrafo</p><p>Segundo parágrafo</p></body></html>\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Extraindo todos os parágrafos\n",
    "paragrafos = soup.find_all('p')\n",
    "\n",
    "for p in paragrafos:\n",
    "    print(p.text) # print the text inside the <p> tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto do link: Clique aqui\n",
      "URL do link: https://example.com\n"
     ]
    }
   ],
   "source": [
    "html = \"<html><body><a href='https://example.com'>Clique aqui</a></body></html>\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Extraindo o link\n",
    "link = soup.a.text\n",
    "url = soup.a['href']\n",
    "\n",
    "print(f\"Texto do link: {link}\")\n",
    "print(f\"URL do link: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item 1', 'Item 2', 'Item 3']\n"
     ]
    }
   ],
   "source": [
    "html = \"<html><body><ul><li>Item 1</li><li>Item 2</li><li>Item 3</li></ul></body></html>\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Extraindo todos os itens da lista\n",
    "itens = [li.text for li in soup.find_all('li')]\n",
    "print(itens) # print all items in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo em destaque\n"
     ]
    }
   ],
   "source": [
    "html = \"<html><body><div class='destaque'>Conteúdo em destaque</div></body></html>\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Extraindo o conteúdo da div com a classe 'destaque'\n",
    "conteudo = soup.find('div', class_='destaque').text\n",
    "print(conteudo) # print the content of the div with the class 'destaque'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Notícia 1', 'Notícia 2', 'Notícia 3']\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div class=\"noticia\">Notícia 1</div>\n",
    "        <div class=\"noticia\">Notícia 2</div>\n",
    "        <div class=\"noticia\">Notícia 3</div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Extraindo todas as divs com a classe 'noticia'\n",
    "noticias = [div.text for div in soup.find_all('div', class_='noticia')]\n",
    "print(noticias) # print all news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nome', 'Idade']\n",
      "['João', '25']\n",
      "['Maria', '30']\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<table>\n",
    "    <tr><th>Nome</th><th>Idade</th></tr>\n",
    "    <tr><td>João</td><td>25</td></tr>\n",
    "    <tr><td>Maria</td><td>30</td></tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Extraindo os dados da tabela\n",
    "linhas = soup.find_all('tr') # get all rows in the table\n",
    "\n",
    "for linha in linhas:\n",
    "    colunas = linha.find_all(['th', 'td']) # get all columns in the row\n",
    "    dados = [col.text for col in colunas]\n",
    "    print(dados) # print the data in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "“A day without sunshine is like, you know, night.”\n"
     ]
    }
   ],
   "source": [
    "#Web Scraping no Site quotes.toscrape.com\n",
    "\n",
    "# Site com citações de autores famosos\n",
    "url = \"http://quotes.toscrape.com\"\n",
    "html = urllib.request.urlopen(url).read()\n",
    "\n",
    "#Criando o objeto BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Extraindo as citações\n",
    "for quote in soup.find_all('span', class_='text'):\n",
    "    print(quote.text) # print the quote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "J.K. Rowling\n",
      "Albert Einstein\n",
      "Jane Austen\n",
      "Marilyn Monroe\n",
      "Albert Einstein\n",
      "André Gide\n",
      "Thomas A. Edison\n",
      "Eleanor Roosevelt\n",
      "Steve Martin\n"
     ]
    }
   ],
   "source": [
    "# Extraindo os autores\n",
    "for author in soup.find_all('small', class_='author'):\n",
    "    print(author.text) # print the author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miracles\n",
      "miracle\n",
      "love\n",
      "choices\n",
      "paraphrased\n",
      "obvious\n",
      "humor\n",
      "edison\n",
      "deep-thoughts\n",
      "friendship\n",
      "life\n",
      "simile\n",
      "value\n",
      "inspirational\n",
      "reading\n",
      "books\n",
      "change\n",
      "aliteracy\n",
      "abilities\n",
      "classic\n",
      "adulthood\n",
      "truth\n",
      "friends\n",
      "world\n",
      "misattributed-eleanor-roosevelt\n",
      "thinking\n",
      "success\n",
      "be-yourself\n",
      "failure\n",
      "live\n"
     ]
    }
   ],
   "source": [
    "# Extraindo todas as tags usadas nas citações\n",
    "\n",
    "tags = set()\n",
    "for tag in soup.find_all('a', class_='tag'):\n",
    "    tags.add(tag.text)\n",
    "\n",
    "for tag in tags:\n",
    "    print(tag) # print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "love\n",
      "\n",
      "\n",
      "inspirational\n",
      "\n",
      "\n",
      "life\n",
      "\n",
      "\n",
      "humor\n",
      "\n",
      "\n",
      "books\n",
      "\n",
      "\n",
      "reading\n",
      "\n",
      "\n",
      "friendship\n",
      "\n",
      "\n",
      "friends\n",
      "\n",
      "\n",
      "truth\n",
      "\n",
      "\n",
      "simile\n",
      "\n",
      "['love', 'inspirational', 'life', 'humor', 'books', 'reading', 'friendship', 'friends', 'truth', 'simile']\n"
     ]
    }
   ],
   "source": [
    "top_tags = soup.find_all('span', class_='tag-item')\n",
    "for tag in top_tags:\n",
    "    print(tag.text) # print the top tags\n",
    "\n",
    "# transformar em uma lista\n",
    "\n",
    "top_tags = [tag.text.strip() for tag in soup.find_all('span', class_='tag-item')]\n",
    "print(top_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               quote             author\n",
      "0  “The world as we have created it is a process ...    Albert Einstein\n",
      "1  “It is our choices, Harry, that show what we t...       J.K. Rowling\n",
      "2  “There are only two ways to live your life. On...    Albert Einstein\n",
      "3  “The person, be it gentleman or lady, who has ...        Jane Austen\n",
      "4  “Imperfection is beauty, madness is genius and...     Marilyn Monroe\n",
      "5  “Try not to become a man of success. Rather be...    Albert Einstein\n",
      "6  “It is better to be hated for what you are tha...         André Gide\n",
      "7  “I have not failed. I've just found 10,000 way...   Thomas A. Edison\n",
      "8  “A woman is like a tea bag; you never know how...  Eleanor Roosevelt\n",
      "9  “A day without sunshine is like, you know, nig...       Steve Martin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extraindo as citações\n",
    "quotes = [quote.text for quote in soup.find_all('span', class_='text')]\n",
    "# Extraindo os autores\n",
    "authors = [author.text for author in soup.find_all('small', class_='author')]\n",
    "\n",
    "# Criando um DataFrame\n",
    "df = pd.DataFrame({'quote': quotes, 'author': authors})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando csv\n",
    "df.to_csv('quotes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
